# ğŸ—‚ï¸ Data Cleaning & Preparation Project â€“ Kaggle Data Science & ML Survey

## ğŸ“– Project Story â€“ Before the Cleaning Began

### 1. The Beginning

This journey started with a deceptively simple-looking dataset â€” the Kaggle Data Science & ML Survey (covering 2017â€“2021). At first glance, it looked like a goldmine of insights waiting to be unlocked. But as soon as we peeked under the hood, we realized we weren't just mining for insights â€” we'd need to do serious excavation before we could even start exploring.

**The mission was clear:**

Take this massive, messy, wide survey dataset and make it clean, consistent, and analysis-ready â€” while documenting every step so anyone could reproduce or audit the process later.

### 2. Meet the Data

- **Source:** Kaggle Data Science & ML Survey
- **Original Rows:** 101,846 unique entries (after removing 4,456 duplicates)
- **Original Columns:** ~300 (exact expected count before cleaning: 293)
- **Format:** Multi-choice survey â†’ one column per option

**Challenges spotted immediately:**

- Many blank or all-null columns causing Excel/Power Query to choke
- Inconsistent column naming (mixed casing, cryptic codes like `Q1_Part_1`)
- Performance slowdowns due to extreme dataset width
- "None" / "Other" answer columns scattered throughout
- Missing survey questions Q28â€“Q30 in original data

### 3. The First Strategic Moves

Rather than try to clean all ~300 columns at once, we decided to split the dataset into smaller, logical files to make the work lighter and more systematic. We also wanted to group similar structures together â€” especially "paired" questions â€” so we could apply consistent transformations without fear of breaking unrelated data.

### 4. The Data Separation Plan

We ended up with 5 smaller files, each representing a theme or block of questions:

| File # | Contents |
|--------|----------|
| 1 | **Demographics & General Q** â†’ Demographics + Questions 1-6 |
| 2 | **Questions 7-15** |
| 3 | **Questions 16-26** |
| 4 | **Current vs Future (Paired structure)** â†’ Q27, Q32, Q34, Q36, Q37, Q38 â€” two parts each ("Current Use" and "Future Interest"), with Q28â€“Q30 missing from source |
| 5 | **Questions 31, 33, 35, 39, 40, 41, 42** |

**Why split like this?**

âœ… Faster handling in Power Query & Excel  
âœ… Easier to apply consistent cleaning rules within each block  
âœ… Special handling for "paired" questions without affecting the rest

### 5. Special Handling for Paired Questions

The **Current vs Future** set (File 4) is special because each question appears in two parts, with identical answer options:

- **Part 1:** Tools/tech currently used regularly
- **Part 2:** Tools/tech the respondent wants to learn in the next 2 years

These will be kept in the same sheet, but cleaned with mirrored naming conventions (e.g., `_Now` / `_Future` suffixes). This will make later Power BI visualizations simple and accurate.

### 6. Pre-Cleaning Agreements

Before touching any values, we defined the core rules we'll follow in the cleaning phase:

- **Use a mapping table for renaming** â†’ no manual header edits, all documented
- **Standardize data types** â†’ match field purpose (Text, Number, Date)
- **Handle "None" & "Other"** â†’ consistent prefixes or drop if redundant
- **Tackle missing data strategically** â†’ distinguish between true skips and accidental blanks
- **Document everything** in a change log with the file name as the header
- **Validate final merged file** â†’ must have exactly 293 columns after recombining

### 7. Validation Check Plan â€“ Column Count

**Before cleaning, we will:**

1. Load original downloaded dataset â†’ confirm column count = 293
2. If count differs, investigate before proceeding (check export completeness, hidden columns, or mismatched source)

### 8. What Happens Next

With the strategy locked, we're ready to:

1. **Clean each of the 5 files separately** using the agreed rules
2. **Keep a living change log** so the documentation tells the full story from raw â†’ clean
3. **Merge all files back** into one master dataset
4. **Run validation** to ensure structure matches the original (but cleaner)

The next commit in this project will mark the start of the **Cleaning Phase** â€” where we tame the chaos and shape this into a dataset ready for powerful exploratory analysis.

---

> ğŸ’¡ **Note:** This section is "before cleaning" â€” the story will be expanded with detailed cleaning logs and transformations as each file is processed.

## Project Structure

```
ğŸ“ kaggle-survey-data-cleaning/
â”œâ”€â”€ ğŸ“„ README.md                    # This documentation
â”œâ”€â”€ ğŸ“ raw-data/                    # Original dataset files
â”œâ”€â”€ ğŸ“ split-files/                 # 5 separated file groups
â”‚   â”œâ”€â”€ file1_demographics_q1-6.csv
â”‚   â”œâ”€â”€ file2_q7-15.csv
â”‚   â”œâ”€â”€ file3_q16-26.csv
â”‚   â”œâ”€â”€ file4_current-future-paired.csv
â”‚   â””â”€â”€ file5_remaining-questions.csv
â”œâ”€â”€ ğŸ“ cleaned-data/                # Final clean datasets
â”œâ”€â”€ ğŸ“ documentation/               # Cleaning logs & mapping tables
â””â”€â”€ ğŸ“ validation/                  # Data quality checks
```


## Contributing

This project follows a systematic, documented approach to data cleaning. If you'd like to contribute:

- Follow the established naming conventions
- Document all changes in the appropriate log files
- Ensure validation checks pass before submitting changes

---

# Sheet Cleaning Log â€” Geographic & General Questions

**Source:** Kaggle Data Science Survey (2017â€“2021) â€” Geographic & General Questions tab

---

## 1. Objective

Standardize, map, and validate key demographic and general survey fields to ensure:

- **Clarity** for dashboards and storytelling
- **Reproducibility** for future ETL runs
- **Business-friendly categories** for decision-makers

---

## 2. Actions Taken

### Geographic Fields

#### Country
- Bulk-replaced inconsistent spellings and variants via mapping table (e.g., "United States of America" â†’ "United States")
- Corrected casing and encoding for non-Latin scripts
- Logged all original â†’ clean replacements in ETL documentation

### Demographic & General Fields

#### Education
- Removed encoding issues and excess whitespace
- Standardized into clear academic categories:
  - High School
  - Associate degree
  - Bachelor's degree
  - Master's degree
  - Doctoral degree

#### Years Coding
- Normalized varied range formats into ordered bands:
  - `<1 year`
  - `1â€“2 years`
  - `3â€“5 years`
  - `6â€“9 years`
  - `10+ years`
  - `20+ years`
- Retained "20+ years" as a separate top category for experience-band analysis

#### Career Stage (derived from age ranges)
- Grouped raw age responses into consolidated stages:
  - **Junior**
  - **Mid**
  - **Senior**
  - **Expert**
- Ensured grouping rules are explicit in mapping table

#### Gender (Binary)
- Standardized values to "Male" / "Female" for binary analysis while retaining original text in reference column for inclusivity
- Removed extra spaces, fixed inconsistent casing

### Survey Meta

#### Duration (minutes)
- Converted raw completion time from seconds to minutes (rounded to two decimals)
- Flagged and filtered out extreme outliers (e.g., >180 minutes) as non-representative
- Documented null-handling policy: missing durations kept as blanks for transparency

---

## 3. Validation Steps

- âœ… Ran before/after uniques check for all categorical fields (see summary table below)
- âœ… Cross-verified that mapping tables covered 100% of pre-cleaned values
- âœ… Checked that transformed data matched expected category order for dashboard visuals

---

## 4. Before/After Unique Values â€” Summary

| Field | Unique Values Before Cleaning | Unique Values After Cleaning |
|-------|------------------------------|------------------------------|
| **Country** | Mixed spellings, abbreviations, casing | Standardized title-case country names |
| **Education** | Multiple phrasings & encoding issues | 5 clean academic categories |
| **Years Coding** | Mixed symbols, text ranges, numeric values | Ordered, consistent bands |
| **Career Stage** | Age ranges in years | Grouped into 4 career stages |
| **Gender (Binary)** | Variations of male/female, mixed case | Male / Female |
| **Duration (minutes)** | Raw seconds, blanks | Rounded minutes, outliers flagged |

---

## 5. Business Impact

### âœ… Clarity
No need for last-minute manual edits before analysis

### âœ… Scalability
Mapping tables make adding new survey years effortless

### âœ… Traceability
Each transformation decision is recorded for reproducibility

---

## Files Modified

```
ğŸ“ cleaned-data/
â”œâ”€â”€ geographic_general_questions_cleaned.csv
ğŸ“ documentation/
â”œâ”€â”€ country_mapping_table.csv
â”œâ”€â”€ education_mapping_table.csv
â”œâ”€â”€ coding_experience_mapping_table.csv
â”œâ”€â”€ career_stage_mapping_table.csv
â””â”€â”€ gender_mapping_table.csv
```

## Quality Metrics

| Metric | Result |
|--------|--------|
| **Data Completeness** | 98.7% (missing values documented) |
| **Mapping Coverage** | 100% (all original values mapped) |
| **Validation Checks** | âœ… All passed |
| **Outliers Handled** | 342 extreme duration values flagged |

---

## Next Steps

1. **Integration** with other cleaned sheet files
2. **Final validation** of merged dataset
3. **Dashboard preparation** with clean, consistent categories

---

**Status:** ğŸš§ Pre-Cleaning Phase Complete | Next: Data Cleaning Implementation
